{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Can we get data near the [Coastal Endurance](http://oceanobservatories.org/array/coastal-endurance/) array?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Time span to get the data (&plusmn;4 days)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "now = datetime.utcnow()\n",
    "start = now - timedelta(days=4)\n",
    "stop = now + timedelta(days=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Bounding box: everything inside the Oregon Line (44&deg;35'N, 125&deg;W) and Washington Line (47&deg;N, 125&deg;W)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bbox = [-125, 44.583, -123.75, 47]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Variable: sea water temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utilities import CF_names\n",
    "\n",
    "sos_name = 'sea_water_temperature'\n",
    "name_list = CF_names[sos_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assemble `fes` filter with `a`+`b`+`c`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from owslib import fes\n",
    "from utilities import fes_date_filter\n",
    "\n",
    "kw = dict(wildCard='*',\n",
    "          escapeChar='\\\\',\n",
    "          singleChar='?',\n",
    "          propertyname='apiso:AnyText')\n",
    "\n",
    "or_filt = fes.Or([fes.PropertyIsLike(literal=('*%s*' % val), **kw)\n",
    "                  for val in name_list])\n",
    "\n",
    "begin, end = fes_date_filter(start, stop)\n",
    "filter_list = [fes.And([begin, end, fes.BBox(bbox), or_filt])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate `csw` object using the NGDC catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from owslib.csw import CatalogueServiceWeb\n",
    "\n",
    "csw = CatalogueServiceWeb('http://www.ngdc.noaa.gov/geoportal/csw',\n",
    "                          timeout=60)\n",
    "\n",
    "csw.getrecords2(constraints=filter_list, maxrecords=1000, esn='full')\n",
    "\n",
    "fmt = '{:*^64}'.format\n",
    "print(fmt(' Catalog information '))\n",
    "print(\"CSW version: {}\".format(csw.version))\n",
    "print(\"Number of datasets available: {}\".format(len(csw.records.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did we get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utilities import service_urls\n",
    "\n",
    "dap_urls = service_urls(csw.records, service='odp:url')\n",
    "sos_urls = service_urls(csw.records, service='sos:url')\n",
    "\n",
    "print(fmt(' SOS '))\n",
    "for url in sos_urls:\n",
    "    print('{}'.format(url))\n",
    "\n",
    "print(fmt(' DAP '))\n",
    "for url in dap_urls:\n",
    "    print('{}.html'.format(url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found [`CO-OPS`](http://opendap.co-ops.nos.noaa.gov/) and [`NDBC`](http://www.ndbc.noaa.gov/) observations available in the [`SOS`](http://www.opengeospatial.org/standards/sos) schema and one model available in OPeNDAP.\n",
    "\n",
    "OPeNDAP URLs can be fed directly to any OPenDAP client,\n",
    "but there is a gap between finding the SOS endpoint and actually downloading the data.\n",
    "We can bridge that gap using `pyoos`'s collectors (`NdbcSos` and `CoopsSos`).\n",
    "\n",
    "PS: We should automate this step.  (See https://github.com/SECOORA/secoora/issues/232.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get NDBC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyoos.collectors.ndbc.ndbc_sos import NdbcSos\n",
    "\n",
    "collector_ndbc = NdbcSos()\n",
    "\n",
    "collector_ndbc.set_bbox(bbox)\n",
    "collector_ndbc.end_time = stop\n",
    "collector_ndbc.start_time = start\n",
    "collector_ndbc.variables = [sos_name]\n",
    "\n",
    "ofrs = collector_ndbc.server.offerings\n",
    "title = collector_ndbc.server.identification.title\n",
    "print(fmt(' NDBC Collector offerings '))\n",
    "print('{}: {} offerings'.format(title, len(ofrs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from owslib.ows import ExceptionReport\n",
    "from utilities import collector2table, get_ndbc_longname\n",
    "\n",
    "try:\n",
    "    ndbc = collector2table(collector=collector_ndbc)\n",
    "\n",
    "    names = []\n",
    "    for s in ndbc['station']:\n",
    "        try:\n",
    "            name = get_ndbc_longname(s)\n",
    "        except ValueError:\n",
    "            name = s\n",
    "        names.append(name)\n",
    "\n",
    "    ndbc['name'] = names\n",
    "\n",
    "    ndbc.set_index('name', inplace=True)\n",
    "except ExceptionReport:\n",
    "    ndbc = DataFrame()\n",
    "\n",
    "ndbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get COOPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyoos.collectors.coops.coops_sos import CoopsSos\n",
    "\n",
    "collector_coops = CoopsSos()\n",
    "\n",
    "collector_coops.set_bbox(bbox)\n",
    "collector_coops.end_time = stop\n",
    "collector_coops.start_time = start\n",
    "collector_coops.variables = [sos_name]\n",
    "\n",
    "ofrs = collector_coops.server.offerings\n",
    "title = collector_coops.server.identification.title\n",
    "print(fmt(' Collector offerings '))\n",
    "print('{}: {} offerings'.format(title, len(ofrs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utilities import get_coops_metadata\n",
    "\n",
    "try:\n",
    "    coops = collector2table(collector=collector_coops)\n",
    "\n",
    "    names = []\n",
    "    for s in coops['station']:\n",
    "        try:\n",
    "            name = get_coops_metadata(s)[0]\n",
    "        except ValueError:\n",
    "            name = s\n",
    "        names.append(name)\n",
    "\n",
    "    coops['name'] = names\n",
    "\n",
    "    coops.set_index('name', inplace=True)\n",
    "except ExceptionReport:\n",
    "    coops = DataFrame()\n",
    "\n",
    "coops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can merge everything that we found into one table before we start downloading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import concat\n",
    "\n",
    "all_obs = concat([coops, ndbc])\n",
    "\n",
    "all_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custom function `pyoos2df` uses the `pyoos` collector to download each observation found as a `pandas.DataFrame`.\n",
    "We accumulate all the DataFrames into the dictionary `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utilities import pyoos2df\n",
    "\n",
    "data = dict()\n",
    "col = 'sea_water_temperature (C)'\n",
    "for station in all_obs.index:\n",
    "    try:\n",
    "        idx = all_obs['station'][station]\n",
    "        df = pyoos2df(collector_ndbc, idx, df_name=station)\n",
    "        if df.empty:\n",
    "            df = pyoos2df(collector_coops, idx, df_name=station)\n",
    "        data.update({idx: df[col]})\n",
    "    except ExceptionReport as e:\n",
    "        print(\"[{}] {}:\\n{}\".format(idx, station, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the data we found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(13, 3.25))\n",
    "\n",
    "colors = seaborn.color_palette(\"Set2\", len(data))\n",
    "for k, (key, series) in enumerate(data.items()):\n",
    "    station_name = all_obs.index[all_obs['station'] == key][0]\n",
    "    series.plot(ax=ax, label=station_name, color=colors[k])\n",
    "    ax.legend(bbox_to_anchor=(1.35, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```python\n",
    "from utilities import is_station\n",
    "\n",
    "non_stations = []\n",
    "for url in dap_urls:\n",
    "    try:\n",
    "        if not is_station(url):\n",
    "            non_stations.append(url)\n",
    "    except RuntimeError as e:\n",
    "        print(\"Could not access URL {}. {!r}\".format(url, e))\n",
    "\n",
    "dap_urls = non_stations\n",
    "\n",
    "print(fmt(' Filtered DAP '))\n",
    "for url in dap_urls:\n",
    "    print('{}.html'.format(url))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "from utilities import quick_load_cubes, get_surface, get_model_name\n",
    "\n",
    "url = dap_urls[0]\n",
    "\n",
    "cube = quick_load_cubes(url, name_list, callback=None, strict=True)\n",
    "cube = get_surface(cube)\n",
    "mod_name, model_full_name = get_model_name(cube, url)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we found only one model let's just its mesh.\n",
    "For that we will need to use `pyugrid` (this is a UGRID compliant model).\n",
    "\n",
    "PS: I use matplotlib for the triangulation because it is faster than `pyugrid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyugrid\n",
    "import matplotlib.tri as tri\n",
    "\n",
    "ugrid = pyugrid.UGrid.from_ncfile(url)\n",
    "lon = ugrid.nodes[:, 0]\n",
    "lat = ugrid.nodes[:, 1]\n",
    "triangles = ugrid.faces[:]\n",
    "triang = tri.Triangulation(lon, lat, triangles=triangles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two cells creates a PNG image with the mesh and saves a trimmed version that we can use as a map layer.\n",
    "\n",
    "Note that we could use more geo-friendly vector formats, like GeoJSON, but due to the large numbers of elements in the mesh it is lighter to use a raster overlay instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "bounds = lon.min(), lon.max(), lat.min(), lat.max()\n",
    "\n",
    "def make_map(bbox, projection=ccrs.Mercator()):\n",
    "    fig, ax = plt.subplots(subplot_kw=dict(projection=projection))\n",
    "    ax.set_extent(bounds)\n",
    "    return fig, ax\n",
    "\n",
    "fig, ax = make_map(bbox, projection=ccrs.PlateCarree())\n",
    "kw = dict(linestyle='-', color='darkgray', linewidth=0.5)\n",
    "ax.triplot(triang, **kw)\n",
    "ax.axis('off')\n",
    "\n",
    "fig.savefig('mesh.png', transparent=True, dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageChops\n",
    "\n",
    "\n",
    "def trim(fname):\n",
    "    img = Image.open(fname)\n",
    "    img = img.convert('RGBA')\n",
    "    datas = img.getdata()\n",
    "\n",
    "    new_data = []\n",
    "    for item in datas:\n",
    "        if item[0] == 255 and item[1] == 255 and item[2] == 255:\n",
    "            new_data.append((255, 255, 255, 0))\n",
    "        else:\n",
    "            new_data.append(item)\n",
    "    img.putdata(new_data)\n",
    "    \n",
    "    border = Image.new(img.mode, img.size, img.getpixel((0, 0)))\n",
    "    diff = ImageChops.difference(img, border)\n",
    "    diff = ImageChops.add(diff, diff, 2.0, -100)\n",
    "    bbox = diff.getbbox()\n",
    "    if bbox:\n",
    "        img = img.crop(bbox)\n",
    "    return np.array(img)\n",
    "\n",
    "img = trim('mesh.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the pieces let's create an interactive map with all this information.\n",
    "\n",
    "First the `Map` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "import numpy as np\n",
    "\n",
    "location = np.array(bbox).reshape(2, 2).mean(axis=0).tolist()[::-1]\n",
    "tiles = ('http://services.arcgisonline.com/arcgis/rest/'\n",
    "         'services/Ocean/World_Ocean_Base/MapServer/tile/{z}/{y}/{x}')\n",
    "\n",
    "mapa = folium.Map(location=location, zoom_start=7, tiles=tiles, attr='ESRI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time-series (as html `bokeh` plots)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure\n",
    "from bokeh.resources import CDN\n",
    "from bokeh.embed import file_html\n",
    "\n",
    "from folium.element import IFrame\n",
    "\n",
    "def make_marker(key):\n",
    "    width, height = 500, 250\n",
    "    station_name = all_obs.index[all_obs['station'] == key][0]\n",
    "    \n",
    "    p = figure(x_axis_type=\"datetime\",\n",
    "               title=station_name,\n",
    "               width=width, height=height)\n",
    "    p.line(data[key].index, data[key], line_width=2)\n",
    "    html = file_html(p, CDN, key)\n",
    "    iframe = IFrame(html, width=width+40, height=height+80)\n",
    "    \n",
    "    pos = (all_obs[all_obs['station'] == key]['lat'][0],\n",
    "           all_obs[all_obs['station'] == key]['lon'][0])\n",
    "    \n",
    "    popup = folium.Popup(iframe, max_width=2650)\n",
    "    icon = folium.Icon(color='green', icon='stats')\n",
    "    marker = folium.Marker(pos, popup=popup, icon=icon)\n",
    "    return marker\n",
    "\n",
    "for key in data.keys():\n",
    "    make_marker(key).add_to(mapa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A region bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "box = folium.PolyLine([[bbox[1], bbox[0]], [bbox[1], bbox[2]],\n",
    "                       [bbox[3], bbox[2]], [bbox[3], bbox[0]],\n",
    "                       [bbox[1], bbox[0]]], color='red')\n",
    "box.add_to(mapa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model mesh (raster layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from folium import plugins\n",
    "\n",
    "with Dataset(url) as nc:\n",
    "    title = nc.title\n",
    "\n",
    "mesh = plugins.ImageOverlay(img,\n",
    "                            bounds=[[lat.min(), lon.min()],\n",
    "                                    [lat.max(), lon.max()]],\n",
    "                            opacity=0.5)\n",
    "\n",
    "folium.Popup(title).add_to(mesh)\n",
    "mesh.add_to(mapa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the full map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the original Endurance Array image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://oceanobservatories.org/wp-content/uploads/2011/04/Endurance-Array-Map_2013_04-17_ver_0-02.jpg)"
   ]
  }
 ],
 "metadata": {
  "gist_id": "727e00bb5ad27e022034",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
